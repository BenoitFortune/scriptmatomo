#!/usr/bin/env python3
# coding: utf-8


import requests
import csv
import os

OUTPUT_DIR = "extract_ch"
OUTPUT_FILE = "stories.csv"
URL_API = "https://api.clubhouse.io"
QUERY_PROJECT = "/api/v3/search/stories?query=project:22977"
QUERY_STATES = '/api/v3/workflows'
QUERY_US = '/api/v3/stories/'
QUERY_EPICS = '/api/v3/epics'
HEADERS = {'Clubhouse-Token': os.environ.get('CLUBHOUSE_TOKEN', '{{ pillar.apikeys.clubhouse|trim }}')}


# fonction pour requêter l'api clubhouse en utilisant les constantes en début de script
def get_data(query):
    url = URL_API + query
    r = requests.get(url, headers=HEADERS)
    r.raise_for_status()
    return r.json()


# fonction qui extrait les id CH des tickets reliés à la demande, les compare avec l'id CH de la demande
# puis supprime l'id non pertinent.
# cela permet ensuite de récupérer les bons liens vers les us liées à la demande
def get_story_links(item):
    story_id = item['id']
    s_l = item['story_links']
    lk = ''
    for item in s_l:
        x = item['subject_id']
        if x == story_id:
            lk = str(item['object_id'])
        else:
            lk = str(item['subject_id'])
    return lk


# on récupère l'id retourné par la fonction get_story_links
# on va ensuite chercher le workflow state et l'epic où se situe l'us
def get_story_info(links):
    user_story = get_data(QUERY_US + str(links))
    return [user_story['workflow_state_id'], user_story['epic_id']]


def main():
    # on crée un dictionnaire avec l'id du workflow en clé et son nom en valeur
    all_my_states = {state['id']: state['name'] for item in get_data(QUERY_STATES) for state in item['states']}

    # on récupère la liste des epics pour les mettre dans un dictionnaire en mettant l'id en clé
    all_my_epics = {item['id']: item['name'] for item in get_data(QUERY_EPICS)}

    # on récupère l'ensemble des us pour les mettre dans un même objet
    search_results = get_data(QUERY_PROJECT)
    pages_of_search_results = []

    while search_results['next'] is not None:
        pages_of_search_results.extend(search_results['data'])
        search_results = get_data(search_results['next'])
    else:
        pages_of_search_results.extend(search_results['data'])

    # extraction de l'id du ticket, de l'id de l'état, des labels du ticket ainsi que de l'id des us reliées à ce ticket
    # on stocke toutes ces infos dans un seul tableau
    # ATTENTION ce script ne prend pas en compte les cas où une demande serait reliée à plusieurs autres tickets !!
    tableau = []
    all_story_links = []
    for item in pages_of_search_results:
        labels = [l["name"] for l in item["labels"]]
        links = get_story_links(item)
        # le if else suivant permet de prendre en compte les cas où la demande n'a pas de relation avec un autre ticket
        if links == '':
            story_info = ['', '']
        else:
            story_info = get_story_info(links)
        rang = item["external_id"], item["workflow_state_id"], "/".join(labels), item["moved_at"], links, story_info[0], story_info[1]
        tableau.append(list(rang))
        all_story_links.append(links)

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    # on transforme le tableau en csv et on remplace l'id des états par le nom en allant le chercher dans le dictionnaire créé au début du script
    with open(os.path.join(OUTPUT_DIR, OUTPUT_FILE), "w") as out:
        writer = csv.writer(out, delimiter=',', quoting=csv.QUOTE_MINIMAL)
        writer.writerow(['demand_id', 'demand_workflow_state', 'demand_labels', 'demand_date_last_move', 'linked_us_id', 'us_workflow_state', 'us_epic'])
        for story in tableau:
            story[1] = all_my_states[story[1]]
            story[-2] = all_my_states.get(story[-2], "")
            story[-1] = all_my_epics.get(story[-1], "")

            writer.writerow(story)


if __name__ == "__main__":
    main()
